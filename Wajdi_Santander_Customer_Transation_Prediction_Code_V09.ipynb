{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "## Importing the libraries we will need \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import matplotlib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "import warnings\n",
    "from six.moves import urllib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "from scipy.stats import norm, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Loading data files\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating features for the target variable for splitting the data set:\n",
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "babb46e75f396a25e921ab4abec077243cce44de"
   },
   "outputs": [],
   "source": [
    "#Creatig the Target and Train data sets\n",
    "target = train['target']\n",
    "train = train.drop([\"ID_code\", \"target\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will be training a Light GBM model on our data set . The first step will be to do some changes in our input data set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering part :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "dfd26c446ff80f323791fbdbbbf158d355ee7267"
   },
   "outputs": [],
   "source": [
    "##Data Augmentation \n",
    "\n",
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model Prameters. The below values have been selected after a series our Grid Searchs and random searchs of optimal values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "d418b9c44ef2f96b02db44d70aacbca61fe0952f"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.335,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.041,\n",
    "    'learning_rate': 0.0072,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 685,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1\n",
    "        \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "8b4f1d5f4aef4730673a8a6bbb2e828c2f92e2a5",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM Model\n",
      "Fold idx:1\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.909575\tvalid_1's auc: 0.897224\n",
      "[10000]\ttraining's auc: 0.918344\tvalid_1's auc: 0.902479\n",
      "[15000]\ttraining's auc: 0.924576\tvalid_1's auc: 0.903856\n",
      "[20000]\ttraining's auc: 0.930085\tvalid_1's auc: 0.903835\n",
      "Early stopping, best iteration is:\n",
      "[15495]\ttraining's auc: 0.925139\tvalid_1's auc: 0.903952\n",
      "Fold idx:2\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.910387\tvalid_1's auc: 0.889362\n",
      "[10000]\ttraining's auc: 0.91913\tvalid_1's auc: 0.893268\n",
      "[15000]\ttraining's auc: 0.925229\tvalid_1's auc: 0.893912\n",
      "[20000]\ttraining's auc: 0.930739\tvalid_1's auc: 0.894144\n",
      "[25000]\ttraining's auc: 0.935933\tvalid_1's auc: 0.89392\n",
      "Early stopping, best iteration is:\n",
      "[19849]\ttraining's auc: 0.930577\tvalid_1's auc: 0.89421\n",
      "Fold idx:3\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.909662\tvalid_1's auc: 0.899152\n",
      "[10000]\ttraining's auc: 0.918366\tvalid_1's auc: 0.903179\n",
      "[15000]\ttraining's auc: 0.924492\tvalid_1's auc: 0.903863\n",
      "[20000]\ttraining's auc: 0.930035\tvalid_1's auc: 0.903426\n",
      "Early stopping, best iteration is:\n",
      "[14941]\ttraining's auc: 0.924422\tvalid_1's auc: 0.903899\n",
      "Fold idx:4\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.910115\tvalid_1's auc: 0.886347\n",
      "[10000]\ttraining's auc: 0.91884\tvalid_1's auc: 0.890414\n",
      "[15000]\ttraining's auc: 0.924934\tvalid_1's auc: 0.890774\n",
      "[20000]\ttraining's auc: 0.930467\tvalid_1's auc: 0.890582\n",
      "Early stopping, best iteration is:\n",
      "[13234]\ttraining's auc: 0.922876\tvalid_1's auc: 0.890831\n",
      "Fold idx:5\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.90913\tvalid_1's auc: 0.905608\n",
      "[10000]\ttraining's auc: 0.91799\tvalid_1's auc: 0.909416\n",
      "[15000]\ttraining's auc: 0.924156\tvalid_1's auc: 0.909963\n",
      "[20000]\ttraining's auc: 0.929756\tvalid_1's auc: 0.909511\n",
      "Early stopping, best iteration is:\n",
      "[15154]\ttraining's auc: 0.924331\tvalid_1's auc: 0.909984\n",
      "Fold idx:6\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.9102\tvalid_1's auc: 0.889709\n",
      "[10000]\ttraining's auc: 0.918885\tvalid_1's auc: 0.892973\n",
      "[15000]\ttraining's auc: 0.925018\tvalid_1's auc: 0.893292\n",
      "[20000]\ttraining's auc: 0.930531\tvalid_1's auc: 0.893108\n",
      "Early stopping, best iteration is:\n",
      "[16416]\ttraining's auc: 0.926611\tvalid_1's auc: 0.893363\n",
      "Fold idx:7\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.90952\tvalid_1's auc: 0.896693\n",
      "[10000]\ttraining's auc: 0.918286\tvalid_1's auc: 0.899886\n",
      "[15000]\ttraining's auc: 0.92439\tvalid_1's auc: 0.900058\n",
      "Early stopping, best iteration is:\n",
      "[12077]\ttraining's auc: 0.920959\tvalid_1's auc: 0.90022\n",
      "Fold idx:8\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.909543\tvalid_1's auc: 0.898757\n",
      "[10000]\ttraining's auc: 0.91828\tvalid_1's auc: 0.903039\n",
      "[15000]\ttraining's auc: 0.924426\tvalid_1's auc: 0.90375\n",
      "[20000]\ttraining's auc: 0.92997\tvalid_1's auc: 0.903461\n",
      "Early stopping, best iteration is:\n",
      "[14197]\ttraining's auc: 0.923496\tvalid_1's auc: 0.903812\n",
      "Fold idx:9\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.90967\tvalid_1's auc: 0.901267\n",
      "[10000]\ttraining's auc: 0.918438\tvalid_1's auc: 0.904292\n",
      "[15000]\ttraining's auc: 0.924542\tvalid_1's auc: 0.904366\n",
      "[20000]\ttraining's auc: 0.930044\tvalid_1's auc: 0.903975\n",
      "Early stopping, best iteration is:\n",
      "[13799]\ttraining's auc: 0.92315\tvalid_1's auc: 0.904593\n",
      "Fold idx:10\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.909442\tvalid_1's auc: 0.898901\n",
      "[10000]\ttraining's auc: 0.918254\tvalid_1's auc: 0.901819\n",
      "[15000]\ttraining's auc: 0.924409\tvalid_1's auc: 0.902339\n",
      "[20000]\ttraining's auc: 0.929953\tvalid_1's auc: 0.902135\n",
      "Early stopping, best iteration is:\n",
      "[15294]\ttraining's auc: 0.924736\tvalid_1's auc: 0.902364\n",
      "Fold idx:11\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.909418\tvalid_1's auc: 0.895837\n",
      "[10000]\ttraining's auc: 0.918273\tvalid_1's auc: 0.900361\n",
      "[15000]\ttraining's auc: 0.924509\tvalid_1's auc: 0.900936\n",
      "[20000]\ttraining's auc: 0.930062\tvalid_1's auc: 0.900802\n",
      "Early stopping, best iteration is:\n",
      "[17644]\ttraining's auc: 0.927478\tvalid_1's auc: 0.90118\n",
      "Fold idx:12\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.909216\tvalid_1's auc: 0.897561\n",
      "[10000]\ttraining's auc: 0.917992\tvalid_1's auc: 0.901847\n",
      "[15000]\ttraining's auc: 0.924166\tvalid_1's auc: 0.902441\n",
      "[20000]\ttraining's auc: 0.929721\tvalid_1's auc: 0.90227\n",
      "Early stopping, best iteration is:\n",
      "[16225]\ttraining's auc: 0.925566\tvalid_1's auc: 0.90255\n",
      "Fold idx:13\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.909248\tvalid_1's auc: 0.900445\n",
      "[10000]\ttraining's auc: 0.91798\tvalid_1's auc: 0.903532\n",
      "[15000]\ttraining's auc: 0.924125\tvalid_1's auc: 0.903538\n",
      "Early stopping, best iteration is:\n",
      "[11951]\ttraining's auc: 0.920497\tvalid_1's auc: 0.903733\n",
      "Fold idx:14\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.908569\tvalid_1's auc: 0.906388\n",
      "[10000]\ttraining's auc: 0.917439\tvalid_1's auc: 0.91012\n",
      "[15000]\ttraining's auc: 0.923681\tvalid_1's auc: 0.910474\n",
      "[20000]\ttraining's auc: 0.929336\tvalid_1's auc: 0.909969\n",
      "Early stopping, best iteration is:\n",
      "[14491]\ttraining's auc: 0.923087\tvalid_1's auc: 0.910558\n",
      "Fold idx:15\n",
      "Training until validation scores don't improve for 7000 rounds.\n",
      "[5000]\ttraining's auc: 0.91033\tvalid_1's auc: 0.892989\n",
      "[10000]\ttraining's auc: 0.919025\tvalid_1's auc: 0.896473\n",
      "[15000]\ttraining's auc: 0.925098\tvalid_1's auc: 0.897093\n",
      "[20000]\ttraining's auc: 0.930604\tvalid_1's auc: 0.897264\n",
      "[25000]\ttraining's auc: 0.935821\tvalid_1's auc: 0.896805\n",
      "Early stopping, best iteration is:\n",
      "[20139]\ttraining's auc: 0.930757\tvalid_1's auc: 0.897292\n",
      "CV score: 0.90131 \n"
     ]
    }
   ],
   "source": [
    "num_folds = 15\n",
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]\n",
    "\n",
    "folds = KFold(n_splits=num_folds, random_state=4322789)\n",
    "oof = np.zeros(len(train))\n",
    "getVal = np.zeros(len(train))\n",
    "predictions = np.zeros(len(target))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "print('Light GBM Model')\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    \n",
    "    X_train, y_train = train.iloc[trn_idx][features], target.iloc[trn_idx]\n",
    "    X_valid, y_valid = train.iloc[val_idx][features], target.iloc[val_idx]\n",
    "    \n",
    "    X_tr, y_tr = augment(X_train.values, y_train.values)\n",
    "    X_tr = pd.DataFrame(X_tr)\n",
    "    \n",
    "    print(\"Fold idx:{}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    val_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    \n",
    "    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 7000)\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    getVal[val_idx]+= clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "137cf3c3924422e1a15ac63f4e259b86db86c2c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the Submission File\n"
     ]
    }
   ],
   "source": [
    "num_sub = X\n",
    "print('Saving the Submission File')\n",
    "sub = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "sub[\"target\"] = predictions\n",
    "sub.to_csv('submission{}.csv'.format(num_sub), index=False)\n",
    "getValue = pd.DataFrame(getVal)\n",
    "getValue.to_csv(\"Validation_kfold.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
